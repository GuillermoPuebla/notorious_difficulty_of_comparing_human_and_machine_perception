{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters (learning rate) + Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import seaborn as sns #  pip3 install seaborn==0.9.0\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "res_dir = \"../results/\"\n",
    "fig_dir = \"../figures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results of Kim et al. 2018\n",
    "[Kim, J., Ricci, M., & Serre, T.  (2018). Not-so-clevr: learning sameâ€“different relations strains feedforward neural networks. Interface focus,8(4), 20180011]\n",
    "\n",
    "sort all other results according to that baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(1, 24)\n",
    "problem = [20, 7, 21, 19, 1, 22, 5, 15, 16, 6, 17, 9, 13, 23, 8, 14, 4, 12, 10, 18, 3, 11, 2]\n",
    "\n",
    "kim = np.array([0.5607734806629834, 0.5662983425414365, 0.585635359116022, 0.606353591160221, 0.6215469613259669,\n",
    "0.6367403314917127, 0.6657458563535912, 0.68646408839779, 0.761049723756906, 0.8646408839779005,\n",
    "0.8853591160220995, 0.8908839779005524, 0.9060773480662982, 0.9447513812154695, 0.9502762430939227,\n",
    "0.9709944751381214, 1, 1, 1, 1, 1, 1, 1]) # obtained by webplot digitiser from the figure of Kim et al. 2018\n",
    "\n",
    "\n",
    "def resort_to_kim(res):\n",
    "    \"\"\"\n",
    "    Kim et al. sorted their problems according to accuracy. This function takes a list \n",
    "    with the results [[1, acc1], [2, acc2], ...] and returns the results sorted in the \n",
    "    same way as the results of Kim et al. [acc20, acc7, ...]\n",
    "    \"\"\"\n",
    "    r2 = np.zeros(23)\n",
    "    for r in res:\n",
    "        index = r[0]\n",
    "        value = r[1]\n",
    "        r2[problem.index(index)] = value / 100  # values between 0 and 1\n",
    "    return r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_list(df, method):\n",
    "    \"\"\"\n",
    "    this function gets a df and returns a list containing the results sorted in the order of Kim et al\n",
    "    ARGS:\n",
    "        method: 'val' or 'train' : extract validation or trainingsperformance\n",
    "    \"\"\"\n",
    "    problem = df[\"problem\"].values.tolist()\n",
    "    if method == \"val\":\n",
    "        pc = df[\"pc_val\"].values.tolist()\n",
    "    elif method == \"train\":\n",
    "        pc = df[\"pc_train\"].values.tolist()\n",
    "\n",
    "    res = []\n",
    "    for i in range(len(df)):\n",
    "        res.append([problem[i], pc[i] * 100])\n",
    "    res = resort_to_kim(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_max(res_val, res_train, L):\n",
    "    \"\"\"\n",
    "    return the maximum of the validation performance of the different learningrates\n",
    "    return the corresponding trainingperformance\n",
    "    \"\"\"\n",
    "    a_val = np.array([res_val[L], res_val[L + 1], res_val[L + 2]])\n",
    "    a_train = np.array([res_train[L], res_train[L + 1], res_train[L + 2]])\n",
    "\n",
    "    maxindex = a_val.argmax(axis=0)\n",
    "    max_val = np.zeros(23)\n",
    "    max_train = np.zeros(23)\n",
    "    for i in range(23):\n",
    "        max_val[i] = a_val[maxindex[i]][i]\n",
    "        max_train[i] = a_train[maxindex[i]][i]\n",
    "    return max_val, max_train, maxindex\n",
    "\n",
    "\n",
    "def trans(res_val, res_train, data):\n",
    "    \"\"\"\n",
    "    rearrange the data\n",
    "    \"\"\"\n",
    "    trans_val = np.zeros([23, len(data)])\n",
    "    trans_train = np.zeros([23, len(data)])\n",
    "    trans_index = np.zeros([23, len(data)])  # necessary to get best lr\n",
    "\n",
    "    count = 0\n",
    "    for L in data:\n",
    "        maxi_val, maxi_train, maxindex = get_max(res_val, res_train, L)\n",
    "        for i in range(23):\n",
    "            trans_val[i][count] = maxi_val[i]\n",
    "            trans_train[i][count] = maxi_train[i]\n",
    "            trans_index[i][count] = maxindex[i]\n",
    "        count += 1\n",
    "    return trans_val, trans_train, trans_index\n",
    "\n",
    "\n",
    "def load_resnet(pretrained):\n",
    "    \"\"\"\n",
    "    load results from a .csv file\n",
    "    filter lr and number of training images\n",
    "    returns a list containing the results (for val and train) \n",
    "    for different lr and number of training images as arrays \n",
    "    and the corresponding labels\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_csv(res_dir + \"exp_\" + pretrained + \".csv\")\n",
    "\n",
    "    res_val = []\n",
    "    res_train = []\n",
    "    label = []\n",
    "    for num_train in [28000, 1000, 100]:\n",
    "        if pretrained == 'finetune':\n",
    "            lrs = [0.0003, 0.0001, 0.00006]\n",
    "        elif pretrained == 'scratch':\n",
    "            lrs = [0.001, 0.0006, 0.0003]\n",
    "        for lr in lrs:\n",
    "            df = df_raw.loc[round(df_raw[\"lr\"], 7) == lr]\n",
    "            df = df.loc[df[\"num_trainimages\"] == num_train]\n",
    "\n",
    "            res_val.append(dataframe_to_list(df, \"val\"))\n",
    "            res_train.append(dataframe_to_list(df, \"train\"))\n",
    "            label.append(str(num_train) + \" Images\" + \", lr: \" + str(lr))\n",
    "    return res_val, res_train, label\n",
    "\n",
    "\n",
    "def get_maxindex(res, Ls, lrs):\n",
    "    \"\"\"\n",
    "    This function returns the index of the lr that performs best.\n",
    "    It is used to pick the correct learning rates for the evaluation on the testset (code/network/svrt_test)\n",
    "    \"\"\"\n",
    "    res_val, res_train, label = res\n",
    "    res_val, res_train, transindex = trans(res_val, res_train, Ls)\n",
    "    return transindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare accuracies on validation set to find best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframes containing the accuracies\n",
    "res_s = load_resnet('scratch')\n",
    "res_ft = load_resnet('finetune')\n",
    "\n",
    "indices_lr_ft = get_maxindex(res_ft, [0, 3, 6], [0.0003, 0.0001, 6e-5])\n",
    "indices_lr_s = get_maxindex(res_s, [0, 3, 6], [0.001, 0.0006, 0.0003])\n",
    "print(\"These indices were copied to network_training/svrt_test.py\")\n",
    "print('finetune: ', indices_lr_ft)\n",
    "print('scratch: ', indices_lr_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main figure\n",
    "This shows the accuracy of the different models (Kim et al. + different variations of ResNet) sorted by same-different and spatial tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test_s = np.load(res_dir + \"testset_scratch.npy\")\n",
    "res_test_ft = np.load(res_dir + \"testset_finetune.npy\")\n",
    "\n",
    "\n",
    "def add_to_df(df, acc, network):\n",
    "    return df.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Task type\": [\"same- \\ndifferent \\ntasks\"] * 9\n",
    "                + [\"spatial \\ntasks\"] * 14,\n",
    "                \"Accuracy\": acc,\n",
    "                \"network\": [network] * 23,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"type\": [], \"accuracy\": [], \"network\": []})\n",
    "plot_data = np.array(\n",
    "    [\n",
    "        [kim, \"2-6 layer DNN (Kim et al.)\\n1,000,000 \\nNo\"],\n",
    "        [res_test_ft[:, 0], \"ResNet-50 \\n28,000\\nYes\"],\n",
    "        [res_test_s[:, 0], \"ResNet-50 \\n28,000\\nNo\"],\n",
    "        [res_test_ft[:, 1], \"ResNet-50 \\n1,000\\nYes\"],\n",
    "        [res_test_ft[:, 2], \"ResNet-50 \\n100\\nYes\"],\n",
    "    ]\n",
    ")\n",
    "for acc, network in plot_data:\n",
    "    df = add_to_df(df, acc, network)\n",
    "\n",
    "plt.figure(figsize=[13, 3])\n",
    "fig = sns.stripplot(\n",
    "    x=\"network\",\n",
    "    y=\"Accuracy\",\n",
    "    hue=\"Task type\",\n",
    "    palette=[\"r\", \"b\"],\n",
    "    order=plot_data[:, 1],\n",
    "    jitter=0.1,\n",
    "    dodge=True,\n",
    "    alpha=0.5,\n",
    "    zorder=1,\n",
    "    size=6,\n",
    "    data=df,\n",
    ")\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(loc=(-0.18, 0.27))\n",
    "plt.text(-1.4, 0.426, \"Network:\")\n",
    "plt.text(-1.4, 0.386, \"# of training images:\")\n",
    "plt.text(-1.4, 0.346, \"Pretrained on ImageNet:\")\n",
    "fig.spines[\"top\"].set_visible(False)\n",
    "fig.spines[\"right\"].set_visible(False)\n",
    "# plt.savefig(fig_dir + 'stripplot.pdf', format='pdf', dpi=512, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure in Appendix\n",
    "Accuracy of Resnet is plotted in the same way as by Kim et al. 2018. For each problem the accuracy for different training set sizes is shown by the dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kim_broad():\n",
    "    \"\"\"\n",
    "    replot results of kim et al.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 5))\n",
    "    plt.xticks(x, problem, fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "\n",
    "    plt.tick_params(\n",
    "        axis=\"x\", which=\"both\", bottom=\"off\", top=\"off\",\n",
    "    )\n",
    "    plt.ylim(0.5, 1)\n",
    "\n",
    "    plt.bar(x, kim, color=color, edgecolor=[1, 1, 1], width=0.9, align=\"center\")\n",
    "    plt.bar([1], [0], color=b, edgecolor=[1, 1, 1])\n",
    "    plt.legend(\n",
    "        [\"Same-Different\", \"Spatial\"], loc=2, fontsize=14, bbox_to_anchor=(-0.1, 1.25)\n",
    "    )\n",
    "    fig.axes[0].spines[\"top\"].set_visible(False)\n",
    "    fig.axes[0].spines[\"right\"].set_visible(False)\n",
    "    plt.margins(x=0.005)\n",
    "    plt.xlabel(\"Problem Label\", fontsize=fontsize)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=fontsize)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def figure_appendix_helper(r_s, r_ft, val_test_train, n1, n2, n3, name):\n",
    "    fig = plot_kim_broad()\n",
    "    lightgreen = (178 / 256, 229 / 256, 207 / 256)\n",
    "\n",
    "    # scratch\n",
    "    for i in range(len(r_s)):\n",
    "        plt.plot(\n",
    "            [i + 0.7, i + 1, i + 1.3], r_s[i], \"-\", color=lightgreen, markersize=markersize, clip_on=False,\n",
    "        )  # line\n",
    "        plt.plot(\n",
    "            [i + 0.7], r_s[i][0], \"o\", color=lightgreen, markersize=markersize, clip_on=False,\n",
    "        )  # first point\n",
    "        plt.plot(\n",
    "            [i + 1, i + 1.3], r_s[i][1:3], \"o\", color=lightgreen, markersize=5, clip_on=False,\n",
    "        )  # other points\n",
    "\n",
    "    # finetune\n",
    "    for i in range(len(r_ft)):\n",
    "        plt.plot(\n",
    "            [i + 0.7, i + 1, i + 1.3], r_ft[i], \"-\", color=\"green\", markersize=markersize, clip_on=False,\n",
    "        )  # line\n",
    "        plt.plot(\n",
    "            [i + 0.7], r_ft[i][0], \"o\", color=\"green\", markersize=markersize, clip_on=False,\n",
    "        )  # first point\n",
    "        plt.plot(\n",
    "            [i + 1, i + 1.3], r_ft[i][1:3], \"o\", color=\"green\", markersize=5, clip_on=False,\n",
    "        )  # other points\n",
    "    plt.title(\"%sperformance: %s - %s - %s\" % (val_test_train, n1, n2, n3), fontsize=fontsize)\n",
    "    # plt.savefig(fig_dir + 'appendix.pdf', format='pdf', dpi=512, bbox_inches='tight')\n",
    "\n",
    "\n",
    "def figure_appendix(res, Ls, name, res_s, Ls_s, res_test_s, res_test_ft):\n",
    "    res_val_ft, res_train_ft, label = res\n",
    "    res_val_ft, res_train_ft, tmp = trans(res_val_ft, res_train_ft, Ls)\n",
    "\n",
    "    res_val_s, res_train_s, label_s = res_s\n",
    "    res_val_s, res_train_s, tmp = trans(res_val_s, res_train_s, Ls_s)\n",
    "    n1 = label[Ls[0] + 1][:-12]\n",
    "    n2 = label[Ls[1] + 1][:-12]\n",
    "    n3 = label[Ls[2] + 1][:-12]\n",
    "\n",
    "    figure_appendix_helper(res_test_s, res_test_ft, \"test\", n1, n2, n3, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 18\n",
    "markersize = 8\n",
    "r = sns.hls_palette(8, l=0.7)[0]\n",
    "b = sns.hls_palette(8, l=0.7)[5]\n",
    "m = sns.hls_palette(8, l=0.7)[6]\n",
    "color = [r, r, r, r, r, r, r, r, r, b, b, b, b, b, m, b, b, b, b, b, b, b, b]\n",
    "\n",
    "figure_appendix(res_ft, [0, 12, 15], 'ft_scratch', res_s, [0, 3, 6], res_test_s, res_test_ft)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
