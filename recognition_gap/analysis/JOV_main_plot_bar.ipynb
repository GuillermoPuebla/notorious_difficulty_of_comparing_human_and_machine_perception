{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Recognition Gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a bar plot figure of the magnitudes and standard deviations of recognition gaps for different experiments. In the manuscript, it is Figure 3B.\n",
    "\n",
    "The figure displays two vertical bars for the recognition gaps\n",
    "evaluated with BagNet-33 on the data from Ullman et al. (2016) and on\n",
    "ImageNet data (Deng et al., 2009). Furthermore, it shows the values\n",
    "found by Ullman et al. (2016) for both machine algorithms (also a\n",
    "vertical bar) as well as for humans (horizonal bar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please specify the path to the most top directory of your recognition\n",
    "gap experiments, i.e. the parent directory of the analysis folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_utils\n",
    "import data_csv_utils\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "path_to_recognition_gap_folder = \"/gpfs01/bethge/home/jborowski/CHAM_recognition_gap/JOV_publication_git_bethgelab/recognition_gap/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# custom imports\n",
    "sys.path.insert(1, path_to_recognition_gap_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnitude and standard deviation of recognition gap for **machine\n",
    "algorithms** and **humans**. The values for the experiments with BagNets\n",
    "correspond to the experiments with joint classes (\"jointClasses\") and\n",
    "corner crops (\"Ullman4\"). The data for the experiments with machine\n",
    "algorithms is taken from Ullman et al. (2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionaries that will be plotted\n",
    "recognitionGapsMachine = {}\n",
    "recognitionGapsMachineStd = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from csv files for the experiments with BagNet\n",
    "for exp_dir_condition, exp_dir_list in data_csv_utils.exp_dir_dict.items():\n",
    "    if exp_dir_condition in [\"Ullman_Ullman4_jointClasses\", \"IN_Ullman4\"]:\n",
    "        # get all the data in one dataframe\n",
    "        all_data_df = data_csv_utils.get_df_from_exp_dir_list(exp_dir_list)\n",
    "        # clean the data such that only data from images which yielded MIRCs is\n",
    "        # contained\n",
    "        all_data_df_real_MIRCs = data_csv_utils.get_df_with_data_from_real_MIRCs_only(\n",
    "            all_data_df)\n",
    "\n",
    "        # calculate the metrics that are displayed in the appendix:\n",
    "        # A. mean and standard deviation of rec_gap\n",
    "        recognitionGapsMachine[exp_dir_condition] = all_data_df_real_MIRCs.mean(\n",
    "            axis=0).rec_gap\n",
    "        recognitionGapsMachineStd[exp_dir_condition] = all_data_df_real_MIRCs.std(\n",
    "            axis=0, ddof=0).rec_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognitionGapsMachine[\"machines_Ullman\"] = 0.14\n",
    "recognitionGapsMachineStd[\"machines_Ullman\"] = 0.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vertical_bar(this_key, x_position, this_label=\"\"):\n",
    "    \"\"\"Plot the vertical bars corresponding to the machine data\n",
    "\n",
    "    Args:\n",
    "        this_key:   string to specify experiment\n",
    "        x_position: position on x-axis\n",
    "        this_label: optional label\n",
    "    \"\"\"\n",
    "    plt.bar(\n",
    "        x_position,\n",
    "        recognitionGapsMachine[this_key],\n",
    "        plot_utils.width,\n",
    "        yerr=recognitionGapsMachineStd[this_key],\n",
    "        color=\"white\",\n",
    "        edgecolor=\"k\",\n",
    "        label=this_label\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_axes(ax):\n",
    "    \"\"\"Adjust the axes.\n",
    "\n",
    "    Args:\n",
    "        ax: axes of plot\n",
    "        \"\"\"\n",
    "    ax.set_ylabel(\"recognition gap\")\n",
    "    ax.yaxis.label.set_color(\"red\")\n",
    "    ax.set_xticks(list(range(len(recognitionGapsMachine))))\n",
    "    ax.set_xticklabels(\n",
    "        (\n",
    "            \"BagNet-33\\non data from\\nUllman et al.\",\n",
    "            \"BagNet-33\\non ImageNet\\nsubset\",\n",
    "            \"algorithms from\\nUllman et al.\\non their data\"\n",
    "        ),\n",
    "    )\n",
    "    ax.set_xlim(-0.5, len(recognitionGapsMachine) - 1 + 0.5)\n",
    "\n",
    "    plot_utils.hide_right_and_top_spine(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_legend():\n",
    "    \"\"\"Adjust the legend\"\"\"\n",
    "    legend = plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    # set the color of \"recognition\\ngap\" in the legend red\n",
    "    for i, text in enumerate(legend.get_texts()):\n",
    "        if i == 1:\n",
    "            text.set_color(\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[5, 4.5])\n",
    "\n",
    "# plot horizontal bar for recognition gaps of humans\n",
    "plot_utils.plot_human_rec_gap_as_horizonal_bar(len(recognitionGapsMachine))\n",
    "\n",
    "# plot vertical bars for recognition gaps of machines\n",
    "plot_vertical_bar(\"Ullman_Ullman4_jointClasses\", 0, \"recognition\\ngap\")\n",
    "plot_vertical_bar(\"IN_Ullman4\", 1)\n",
    "plot_vertical_bar(\"machines_Ullman\", 2)\n",
    "\n",
    "customize_axes(plt.axes())\n",
    "customize_legend()\n",
    "\n",
    "# save the figure and display it\n",
    "plt.savefig(\"JOV_main_bar.svg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
