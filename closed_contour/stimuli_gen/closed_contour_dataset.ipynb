{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to generate the images used for the \"Closed Contour experiment\"\n",
    "author: Christina Funke  \n",
    "\n",
    "This notebook generates the full data sets of all possible variations. Alternativly the images of set1 can be generated on-the-fly during the training of the networks (see CHAM/code/network/cc_utils.Dataset_OTF()).  \n",
    "\n",
    "This file uses the files linedrawing_polygon.py, linedrawing_curvy.py and add_background.py.  \n",
    "\n",
    "\n",
    "### Training set\n",
    "set1) is used to train the models (black, Linewidth = 10)\n",
    "\n",
    "**The following data sets are generated:**   \n",
    "validation set (val): 2800 images  \n",
    "test set (test): 5600 images  \n",
    "training set (train): 28000 images  \n",
    "\n",
    "### Variations of this dataset\n",
    "set2) Linewidth = 5  \n",
    "set3) Linewidth = 18  \n",
    "set4) White (Linewidth=10)  \n",
    "set5) BWB (Linewidth = 18)  \n",
    "set6) No flankers (Linewidth = 10)  \n",
    "set7) Noise, 2 lines (noise on circle + remove two lines to get open contour)   \n",
    "set8) Linewidth = 30  \n",
    "set9) Noise, 1 line (noise on circle + remove one line to get open contour (a1))  \n",
    "set10) 3-edge polygons  \n",
    "set11) 6-edge polygons  \n",
    "set12) 9-edge polygons  \n",
    "set13) 12-edge polygons  \n",
    "*[sets 14 to 16 don't exist]*   \n",
    "set17) Curved (equal linewidth, 50-100px)   \n",
    "set18) Dashed (equal linewidth, 50-100px)  \n",
    "set19) Dashed flanker (equal linewidth, 50-100px)  \n",
    "set20) 50 px diameter (curved)  \n",
    "set21) 100 px diameter (curved)  \n",
    "set22) 150 px diameter (curved)  \n",
    "set23) Curved (50 px diameter) + 1 -4 flankers  \n",
    "set24) only two-line flankers: One short, one long line  \n",
    "set25) binarised image  \n",
    "\n",
    "**The following data sets are generated:**     \n",
    "test set (test): 5600 images   \n",
    "\n",
    "#### Remarks\n",
    "1) When generating the images on the fly during the training of the network (-otf=1), it's not necessary to generate a training set. To generate only the validation and test set remove \"train\" from the list in the files linedrawing_polygon.py and add_background.py: methods = [\"val\", \"test\", \"train\"] \n",
    "\n",
    "2) To generate only images with grey background set all_contrast_levels=True. If you want to add a image to the background set this parameter to False.  \n",
    "\n",
    "3) The images in the share folder of the sets 14-23 are different from the ones that are generated by this code. Reason: The seed was different (there used to be a loop over the set_num and the seed was defined outside of this loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import linedrawing_polygon\n",
    "import linedrawing_curvy\n",
    "import add_background\n",
    "\n",
    "set_nums = list(range(1, 14)) + list(\n",
    "    range(17, 26)\n",
    ")  # all available variations of the data set, \n",
    "\n",
    "# if you don't want to generate the generalisation data sets, uncomment the following line\n",
    "# set_nums = [1] \n",
    "\n",
    "debug = True  # set this to True to generate fewer images\n",
    "all_contrast_levels = (\n",
    "    False  # set this to True to reproduce the experiment in the appendix\n",
    ")\n",
    "\n",
    "top_dir = \"../stimuli/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get line drawing for all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_num in set_nums:\n",
    "    if set_num >= 14 and set_num <= 23:\n",
    "        linedrawing_curvy.make_full_dataset(top_dir, set_num, debug=debug)\n",
    "    else:\n",
    "        linedrawing_polygon.make_full_dataset(top_dir, set_num, debug=debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add a background image to all data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from ImageNet\n",
    "margin = 16\n",
    "imagenet_data = torchvision.datasets.ImageFolder(\n",
    "    \"/gpfs01/bethge/data/imagenet-raw/raw-data/train\"\n",
    ")\n",
    "my_transform = transforms.Compose(\n",
    "    [transforms.Scale(256 + 2 * margin), transforms.CenterCrop(256 + 2 * margin)]\n",
    ")\n",
    "imagenet_data.transform = my_transform\n",
    "\n",
    "# add a background image to all data sets\n",
    "for set_num in set_nums:\n",
    "    add_background.make_full_dataset(\n",
    "        top_dir,\n",
    "        set_num,\n",
    "        debug=debug,\n",
    "        all_contrast_levels=all_contrast_levels,\n",
    "        imagenet_data=imagenet_data,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
